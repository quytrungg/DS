{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6852f3",
   "metadata": {
    "colab_type": "text",
    "id": "H3SlxjIe6XAW"
   },
   "source": [
    "# Lab01: Linear Regression.\n",
    "\n",
    "- Student ID: Mai Quý Trung\n",
    "- Student name: 20127370"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1ef91",
   "metadata": {
    "colab_type": "text",
    "id": "33ZcYu4T6XAY"
   },
   "source": [
    "**How to do your homework**\n",
    "\n",
    "\n",
    "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
    "\n",
    "You can discuss the ideas as well as refer to the documents, but *the code and work must be yours*.\n",
    "\n",
    "**How to submit your homework**\n",
    "\n",
    "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
    "\n",
    "Then create a folder named `ID` (for example, if your ID is 1234567, then name the folder `1234567`) Copy file notebook to this folder, compress and submit it on moodle.\n",
    "\n",
    "**Content of the assignment**\n",
    "\n",
    "- Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1095b7",
   "metadata": {
    "colab_type": "text",
    "id": "EbXMeU5Z6XAZ"
   },
   "source": [
    "### 1. The hypothesis set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767378f",
   "metadata": {
    "colab_type": "text",
    "id": "e75OMY0KFpyU"
   },
   "source": [
    "- Linear regression is a **linear** model, e.g. a model that assumes a linear relationship between the input variables (x) and the single output variable (y). More specifically, that y can be calculated from a linear combination of the input variables (x).\n",
    "- Generally, a linear model will make predictions by calculating a weighted sum of the input features (independent variables). \n",
    "$$ \\hat{y}=w_0+w_1x_1+w_2x_2+...+w_nx_n $$\n",
    "    - $\\hat{y}$ is the predicted value.\n",
    "    - $n$ is the number of features.\n",
    "    - $x_i$ is the $i^{th}$ feature value.\n",
    "    - $w_j$ is the $j^{th}$ model parameter (including the bias term $w_0$ and the feature weights $w_1,w_2,...w_n)$.\n",
    "$$\\hat{y}=h_{\\mathbf{w}}\\left(\\mathbf{x}\\right)=\\mathbf{w}^{T}\\cdot\\mathbf{x}$$\n",
    "    - $\\mathbf{w}$ is the model **parameter vector** (including the bias term $w_0$ and the feature weights $w_1,w_2,...w_n$).\n",
    "    - $\\mathbf{w}^T$ is a transpose  of $\\mathbf{w}$ (a row vector insteade of column vector).\n",
    "    - $\\mathbf{x}$ is the instance's **feature vector**, *containing* $x_0$ to $x_n$, with $x_0$ *always equal to* 1.\n",
    "    - $\\mathbf{w}^{T}\\cdot\\mathbf{x}$ is the dot product of $\\mathbf{w}^T$ and $\\mathbf{x}$.\n",
    "    - $h_{\\mathbf{w}}$ is the hypothesis function, using the parameters $\\mathbf{w}$.\n",
    "![Bias](Bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc711f",
   "metadata": {
    "colab_type": "text",
    "id": "_pj4Wci16XAf"
   },
   "source": [
    "### 2. Performance measure and the learning goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89e043",
   "metadata": {
    "colab_type": "text",
    "id": "FNT1Vupf6XAg"
   },
   "source": [
    "- Before we start to train the model, we need to determine how good the model fits the training data. There are a couple of ways to determine the level of quality, but we are going to use the most popular one and that is the **MSE** (Mean Square Error). We need to find the value for $\\mathbf{w}$ that will minimize the MSE:\n",
    "$$\\mathbf{w}=\\arg\\min MSE_{\\mathcal{D}_{train}}$$\n",
    "\n",
    "\n",
    "- MSE on the train set $\\mathcal{D}_{train}$ denoted as $\\left(\\mathbf{X},\\mathbf{y}\\right)$ including m samples $\\left\\{\\left(\\mathbf{x}_1,y_1\\right),\\left(\\mathbf{x}_2,y_2\\right),...\\left(\\mathbf{x}_m,y_m\\right)\\right\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957ba23",
   "metadata": {
    "colab_type": "text",
    "id": "MegJ6-d16XAh"
   },
   "source": [
    "$$MSE\\left(X,h_{\\mathbf{w}}\\right)=\\dfrac{1}{m}\\sum_{i=1}^{m}\\left(\\mathbf{w}^T\\cdot\\mathbf{x}_i - y_i\\right )^2$$\n",
    "$$MSE\\left(X,h_{\\mathbf{w}}\\right)=\\dfrac{1}{m}\\Vert\\mathbf{X}\\mathbf{w}-\\mathbf{y}\\Vert^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419e1fb",
   "metadata": {},
   "source": [
    "Example below is a plot of an MSE function where the true target value is 100, and the predicted values range between -10,000 to 10,000. The MSE loss (Y-axis) reaches its minimum value at prediction (X-axis) = 100. The range is 0 to ∞.\n",
    "![Plot of MSE Loss (Y-axis) vs. Predictions (X-axis)](MSE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266db9b4",
   "metadata": {
    "colab_type": "text",
    "id": "nepVItLQ6XAi"
   },
   "source": [
    "- To find the value of $\\mathbf{w}$ that minimizes the MSE cost function the most common way (*we have known since high school*) is to solve the derivative (gradient) equation. \n",
    "$$\\mathbf{\\hat{w}}=\\left(\\mathbf{X}^T \\cdot \\mathbf{X}\\right)^{\\dagger} \\cdot \\mathbf{X}^T \\cdot \\mathbf{y}$$\n",
    "  - $\\mathbf{\\hat{w}}$ is the value of $\\mathbf{w}$ that minimizes the cost function\n",
    "  - **Notice that** $\\mathbf{X}^T \\cdot \\mathbf{X}$ is not always invertible. $\\left(\\mathbf{X}^T \\cdot \\mathbf{X}\\right)^{\\dagger}$ is pseudo-inverse of $\\left(\\mathbf{X}^T \\cdot \\mathbf{X}\\right)$ - a general case of inverse when the matrix is not invertible or not even square."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f53b1c",
   "metadata": {
    "colab_type": "text",
    "id": "HJAlU8_F6XAj"
   },
   "source": [
    "### 3. Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c338827",
   "metadata": {
    "colab_type": "text",
    "id": "_FuVr94Z6XAk"
   },
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7638d50e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1046891659.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    using LinearAlgebra\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Plots\n",
    "gr()\n",
    "\n",
    "# import your libraries if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2a858",
   "metadata": {
    "colab_type": "text",
    "id": "_6Zd2s_x6XAr"
   },
   "source": [
    "#### Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900febb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rand(1:100, 100)\n",
    "global a = rand(1:5, 1)[1]\n",
    "global b = rand(1:5, 1)[1]\n",
    "\n",
    "f(x) = a*x + b + rand(1:30,1)[1]\n",
    "y = f.(X);\n",
    "print(\"Your regression function: y = $a*x + $b + noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8f0ef",
   "metadata": {
    "colab_type": "text",
    "id": "y1T_LNMb6XAz"
   },
   "source": [
    "#### Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X, y, label=\"data points\", xlabel=\"x\", ylabel=\"y\", title=\"Visualization of data\", legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb81de0",
   "metadata": {
    "colab_type": "text",
    "id": "MPA6J1ED6XA6"
   },
   "source": [
    "**TODO:** \n",
    "\n",
    "- Comment about data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b74718",
   "metadata": {
    "colab_type": "text",
    "id": "-vXaxlpV6XA7"
   },
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de310498",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_linear_regression(X, y)\n",
    "    \"\"\"\n",
    "    Trains Linear Regression on the dataset (X, y).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (m, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    y : numpy array, shape (m, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (d + 1, 1)\n",
    "        The vector of parameters of Linear Regression after training.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct one_added_X \n",
    "# TODO:\n",
    "# First column of one_added_X is all ones (corresponding to x_0).\n",
    "\n",
    "println(\"one_added_X.shape =\", size(one_added_X))\n",
    "println(\"y.shape =\", size(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0eb23",
   "metadata": {
    "colab_type": "text",
    "id": "nVhd2dvCFpzE"
   },
   "source": [
    "#### Train our model and visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = train_linear_regression(one_added_X, y)\n",
    "\n",
    "# Visualize result\n",
    "predicted_ys = one_added_X*w\n",
    "scatter(X, y, xlabel=\"x\", ylabel=\"y\", title=\"Visualization of data\", legend=false)\n",
    "x_min = 0\n",
    "x_max = 100\n",
    "xs = [x_min x_max]'\n",
    "\n",
    "# Construct one_added_xs \n",
    "# TODO:\n",
    "# First column of one_added_xs is all ones (corresponding to x_0).\n",
    "\n",
    "predicted_ys = ones_added_xs*w\n",
    "scatter!(xs, predicted_ys, legend=false)\n",
    "plot!(xs, predicted_ys, legend=false)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "89e8354a88354ecf7ffb299b56239fb0ecc48c48d372ba43f5b93cc4e944f72d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
